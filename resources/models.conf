netflow{
  //spark配置
  appname="Duan_RFModel"
  master="local"
  portmaxRetries=1000
  coresmax=6
  executormemory="800m"

//  数据配置
  nsamplepath="hdfs://spark-s1:9000/spark/data/nsampledataNET"
//  hbase配置
//  zokhost="hadoop"
  zokhost="soc70,soc71,soc72,soc73"
  zokport=2181
  //hdfs配置
  modelpp_path="hdfs://hadoop:9000/spark/model/rfmodelpp"


  base_path="hdfs://spark-s1:9000/spark/"
  res_path="E:\\工作文档\\数据\\test\\"
  netflow_path="hdfs://spark-s1:9000/spark/data/netflow"

  //模型配置
  NumTrees=25
  Impurity="entropy"
  MaxBins=18
  MaxDepth=8
  SubsamplingRate=0.3
  FeatureSubsetStrategy=2
}
moniflow{
  //spark配置
  appname="Duan_NBModel"
  master="local"
  portmaxRetries=1000
  coresmax=6
  executormemory="800m"

  //数据配置
  nsamplepath="hdfs://spark-s1:9000/spark/data/nsampledataMONI"
  //hbase配置
  zokhost="soc70,soc71,soc72,soc73"
  zokport=2181
  //hdfs配置
  modelpp_path="hdfs://spark-s1:9000/spark/model/nbmodelpp"

  base_path="hdfs://spark-s1:9000/spark/"
  res_path="E:\\工作文档\\数据\\test\\"
  hdfs_path="hdfs://bluedon155:9000/spark/model/nbhdfs/"
  moniflow_path="hdfs://spark-s1:9000/spark/data/moniflow"

  #模型配置
  MaxIter=100
  RegParam=0.05
  ElasticNetParam=0.01
}
anomalyDetection{
  //spark配置
  appname="Duan_AnomalyDetection"
  master="local"
  portmaxRetries=1000
  coresmax=6
  executormemory="800m"
  //数据配置
  netflow_path="hdfs://spark-s1:9000/spark/dataNJ/netflow/2017-06-28--2017-06-29"
  res_path="hdfs://spark-s1:9000/spark/data/anomalyDetectionResult/"
  res_local="E:\\工作文档\\数据\\test\\anomalyDetectionResult.csv"
}
IntrusionAudit{
  //spark配置
  appname="Duan_RFModel"
  master="local"
  portmaxRetries=1000
  coresmax=6
  executormemory="800m"
  //es
  esnodes="172.16.12.38"
  esport=9200
  glogIndex="genlog/genlog"
  glogAuditIndex="genlog/audit"
}
AssetAutoFind{
//  sql config
  sql_url="jdbc:postgresql://172.16.10.78:5432/NXSOC5"
  sql_username="postgres"
  sql_password="12345)(*&^%RFVwsx"
//  spark config
  master="local"
  appname="SOC_BigData_Auto"
  portmaxRetries=1000
  coresmax=1
  executormemory="1024m"
//  ES config
//  多个以,分隔
  esnodes="172.16.10.74,172.16.10.75,172.16.10.76"
  esport=9200
}

## this file is config
#aplication.sql.url=jdbc:postgresql://172.16.10.78:5432/NXSOC5
#aplication.sql.username=postgres
#aplication.sql.password=12345)(*&^%RFVwsx
##spark config
#spark.master.url=local
##spark.master.url=spark://soc77:7077
#spark.analyze.app.name=SOC_BigData_Analyze
#spark.auto.app.name=SOC_BigData_Auto
##zookeeper config
#zookeeper.host=soc70,soc71,soc72,soc73
#zookeeper.kafka.host=soc71,soc72,soc73
#zookeeper.port=2181
#kafka.host.list=soc71:9092,soc72:9092,soc73:9092
##kafka config
#kafka.log.topic=log-topic
#kafka.genlog.topic=genlog-topic
#kafka.event.topic=event-topic
#kafka.sinalevent.topic=sinalevent-topic
#kafka.gevent.topic=gevent-topic
#
#kafka.flow.topic=flow-topic
##redis config
#redis.host=172.16.10.70
##ES config
##多个以,分隔
#es.nodes=172.16.10.74,172.16.10.75,172.16.10.76
#es.port=9200
##rule flush time (s)
#redis.rule.reflush=30



//AssetAutoFind{
//  //  sql config
//  sql_url="jdbc:postgresql://10.252.47.214:5432/NXSOC5"
//  sql_username="postgres"
//  sql_password="12345)(*&^%RFVwsx"
//  //  spark config
//  master="spark://aqtsgzpt214:7077"
//  appname="SOC_BigData_Auto"
//  portmaxRetries=1000
//  coresmax=6
//  executormemory="1024m"
//  //  ES config
//  //  多个以,分隔
//  esnodes="10.252.47.208,10.252.47.209,10.252.47.210"
//  esport=9200
//}